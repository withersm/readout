{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Channel Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.formatter.useoffset'] = False\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from scipy.signal import sawtooth, square, savgol_filter\n",
    "import pandas as pd\n",
    "import glob as gl\n",
    "import os\n",
    "import cmath\n",
    "\n",
    "from scipy.signal import sawtooth, square,find_peaks\n",
    "from scipy import spatial\n",
    "# import lambdafit as lf\n",
    "from scipy.interpolate import CubicSpline,interp1d\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm as tqdm_terminal\n",
    "from tqdm.notebook import trange, tqdm_notebook\n",
    "from scipy.signal.windows import hann\n",
    "\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from copy import deepcopy\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Working Function as of 1/29\n",
    "(To include easier parameter option for just single channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_chunk_channels(filename, chunk='all', chunk_start=None, chunk_stop=None, single_channel=None):\n",
    "    # read in file\n",
    "    file = h5py.File(filename, 'r') \n",
    "    # pre-setting range for the for-loop iterating to fix the 0-22 rows of resonator buffer \n",
    "    buffer_range_fixed = range(22, (file['time_ordered_data']['adc_i'].shape[0])) \n",
    "    # iterate depending on chunk argument \n",
    "    if chunk == 'all':\n",
    "        ch = np.array([channel - 22 for channel in buffer_range_fixed])\n",
    "        t = np.array(file['time_ordered_data']['timestamp'])\n",
    "        i = np.array([file['time_ordered_data']['adc_i'][channel] for channel in buffer_range_fixed])\n",
    "        q = np.array([file['time_ordered_data']['adc_q'][channel] for channel in buffer_range_fixed])\n",
    "        \n",
    "    elif chunk == 'some': \n",
    "        ch = np.array([channel - 22 for channel in buffer_range_fixed[chunk_start:chunk_stop]])\n",
    "        t = np.array(file['time_ordered_data']['timestamp'])\n",
    "        i = np.array([file['time_ordered_data']['adc_i'][channel] for channel in buffer_range_fixed[chunk_start:chunk_stop]])\n",
    "        q = np.array([file['time_ordered_data']['adc_q'][channel] for channel in buffer_range_fixed[chunk_start:chunk_stop]])\n",
    "        \n",
    "    elif chunk == 'single':\n",
    "        ch = np.array(buffer_range_fixed[single_channel] - 22)\n",
    "        t = np.array(file['time_ordered_data']['timestamp'])\n",
    "        i = np.array(file['time_ordered_data']['adc_i'][buffer_range_fixed[single_channel]])\n",
    "        q = np.array(file['time_ordered_data']['adc_q'][buffer_range_fixed[single_channel]])\n",
    "        \n",
    "        \n",
    "    result = {'channel': ch, 't': t, 'i': i, 'q': q}\n",
    "                      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for graphing all channels, spaced 10000 apart for inspection\n",
    "\n",
    "def graph_all_channels(channels_data): \n",
    "    for i in range(len(channels_data['i'])):\n",
    "        plt.plot(channels_data['t'],np.abs(channels_data['i'][i]+1j*channels_data['q'][i]) \n",
    "             - np.average(np.abs(channels_data['i'][i]+1j*channels_data['q'][i])) + i*10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LO: 4250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# loading files\n",
    "\n",
    "# time streams\n",
    "testfile_4250_3432 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_4250.0_20240216162215_t_20240216163432.hd5'\n",
    "testfile_4250_3956 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_4250.0_20240216162215_t_20240216163956.hd5'\n",
    "testfile_4250_4412 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_4250.0_20240216162215_t_20240216164412.hd5'\n",
    "\n",
    "# tone initializations\n",
    "tone_init_freq_list_4250 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/freq_list_lo_sweep_targeted_1_fcenter_4250.0_20240216162437.npy'\n",
    "tone_init_sweep_targeted = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_targeted_2_fcenter_4250.0_20240216162651.npy'\n",
    "#testfile = \"/Users/leayamashiro/AliCPT/alicpt_data/data_files/ts_toneinit_fcenter_4250.0_20240506174818_t_20240506191017.hd5\"\n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_4250 = np.load(tone_init_freq_list_4250).real # all values still had +0j \n",
    "freq_list_4250_table = pd.DataFrame(freq_list_4250)\n",
    "freq_list_4250_table.to_csv('freq_list_4250.xlsx')\n",
    "\n",
    "# process data \n",
    "\n",
    "data_4250_3432 = read_hdf5_chunk_channels(testfile_4250_3432)\n",
    "data_4250_3956 = read_hdf5_chunk_channels(testfile_4250_3956)\n",
    "data_4250_4412 = read_hdf5_chunk_channels(testfile_4250_4412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOKING AT THE LO SWEEP FILES TO STUDY DEMOD\n",
    "\n",
    "tone_init_sweep_initial = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_initial_fcenter_4250.0_20240216162224.npy'\n",
    "\n",
    "init_sweep = np.load(tone_init_sweep_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.99875000e+09+0.j, 3.99875100e+09+0.j, 3.99875200e+09+0.j, ...,\n",
       "        3.99924700e+09+0.j, 3.99924800e+09+0.j, 3.99924900e+09+0.j],\n",
       "       [3.99925098e+09+0.j, 3.99925198e+09+0.j, 3.99925298e+09+0.j, ...,\n",
       "        3.99974798e+09+0.j, 3.99974898e+09+0.j, 3.99974998e+09+0.j],\n",
       "       [3.99975195e+09+0.j, 3.99975295e+09+0.j, 3.99975395e+09+0.j, ...,\n",
       "        4.00024895e+09+0.j, 4.00024995e+09+0.j, 4.00025095e+09+0.j],\n",
       "       ...,\n",
       "       [4.50099805e+09+0.j, 4.50099905e+09+0.j, 4.50100005e+09+0.j, ...,\n",
       "        4.50149505e+09+0.j, 4.50149605e+09+0.j, 4.50149705e+09+0.j],\n",
       "       [4.50149902e+09+0.j, 4.50150002e+09+0.j, 4.50150102e+09+0.j, ...,\n",
       "        4.50199602e+09+0.j, 4.50199702e+09+0.j, 4.50199802e+09+0.j],\n",
       "       [4.50200000e+09+0.j, 4.50200100e+09+0.j, 4.50200200e+09+0.j, ...,\n",
       "        4.50249700e+09+0.j, 4.50249800e+09+0.j, 4.50249900e+09+0.j]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_sweep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph data \n",
    "\n",
    "#graph_all_channels(data_4250_3432)\n",
    "#graph_all_channels(data_4250_3956)\n",
    "graph_all_channels(data_4250_4412)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LO: 4750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading files\n",
    "\n",
    "# time streams\n",
    "testfile_4750_5446 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_4750.0_20240216164622_t_20240216165446.hd5'\n",
    "testfile_4750_5853 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_4750.0_20240216164622_t_20240216165853.hd5'\n",
    "testfile_4750_0236 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_4750.0_20240216164622_t_20240216170236.hd5'\n",
    "\n",
    "# tone initializations\n",
    "tone_init_freq_list_4750 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4750.0_20240216164622/freq_list_lo_sweep_targeted_1_fcenter_4750.0_20240216164814.npy'\n",
    "#tone_init_sweep_targeted = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_targeted_2_fcenter_4250.0_20240216162651.npy'\n",
    "#testfile = \"/Users/leayamashiro/AliCPT/alicpt_data/data_files/ts_toneinit_fcenter_4250.0_20240506174818_t_20240506191017.hd5\"\n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_4750 = np.load(tone_init_freq_list_4750).real # all values still had +0j \n",
    "freq_list_4750_table = pd.DataFrame(freq_list_4750)\n",
    "freq_list_4750_table.to_csv('freq_list_4750.xlsx')\n",
    "\n",
    "# process data \n",
    "\n",
    "data_4750_5446 = read_hdf5_chunk_channels(testfile_4750_5446)\n",
    "data_4750_5853 = read_hdf5_chunk_channels(testfile_4750_5853)\n",
    "data_4750_0236 = read_hdf5_chunk_channels(testfile_4750_0236)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph data \n",
    "%matplotlib qt\n",
    "\n",
    "graph_all_channels(data_4750_5446)\n",
    "#graph_all_channels(data_4750_5853)\n",
    "#graph_all_channels(data_4750_0236)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LO: 5250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# loading files\n",
    "\n",
    "# time streams\n",
    "testfile_5250_1735 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_5250.0_20240216170412_t_20240216171735.hd5'\n",
    "testfile_5250_2054 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_5250.0_20240216170412_t_20240216172054.hd5'\n",
    "testfile_5250_3211= '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_5250.0_20240216170412_t_20240216173211.hd5'\n",
    "\n",
    "# tone initializations\n",
    "tone_init_freq_list_5250 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_5250.0_20240216170412/freq_list_lo_sweep_targeted_1_fcenter_5250.0_20240216170918.npy'\n",
    "#tone_init_sweep_targeted = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_targeted_2_fcenter_4250.0_20240216162651.npy'\n",
    "#testfile = \"/Users/leayamashiro/AliCPT/alicpt_data/data_files/ts_toneinit_fcenter_4250.0_20240506174818_t_20240506191017.hd5\"\n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_5250 = np.load(tone_init_freq_list_5250).real # all values still had +0j \n",
    "freq_list_5250_table = pd.DataFrame(freq_list_5250)\n",
    "freq_list_5250_table.to_csv('freq_list_5250.xlsx')\n",
    "\n",
    "# process data \n",
    "\n",
    "data_5250_1735 = read_hdf5_chunk_channels(testfile_5250_1735)\n",
    "data_5250_2054 = read_hdf5_chunk_channels(testfile_5250_2054)\n",
    "data_5250_3211 = read_hdf5_chunk_channels(testfile_5250_3211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph data \n",
    "%matplotlib qt\n",
    "\n",
    "#graph_all_channels(data_5250_1735)\n",
    "#graph_all_channels(data_5250_2054)\n",
    "graph_all_channels(data_5250_3211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LO: 5750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# loading files\n",
    "\n",
    "# time streams\n",
    "#testfile_5750_3932 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_5750.0_20240216173351_t_20240216173932.hd5'\n",
    "testfile_5750_4338 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_5750.0_20240216173351_t_20240216174338.hd5'\n",
    "testfile_5750_4612 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_5750.0_20240216173351_t_20240216174612.hd5'\n",
    "\n",
    "# tone initializations\n",
    "tone_init_freq_list_5750 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_5750.0_20240216173351/freq_list_lo_sweep_targeted_1_fcenter_5750.0_20240216173515.npy'\n",
    "#tone_init_sweep_targeted = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_targeted_2_fcenter_4250.0_20240216162651.npy'\n",
    "#testfile = \"/Users/leayamashiro/AliCPT/alicpt_data/data_files/ts_toneinit_fcenter_4250.0_20240506174818_t_20240506191017.hd5\"\n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_5750 = np.load(tone_init_freq_list_5750).real # all values still had +0j \n",
    "freq_list_5750_table = pd.DataFrame(freq_list_5750)\n",
    "freq_list_5750_table.to_csv('freq_list_5750.xlsx')\n",
    "\n",
    "# # process data \n",
    "\n",
    "# data_5750_3932 = read_hdf5_chunk_channels(testfile_5750_3932)\n",
    "data_5750_4338= read_hdf5_chunk_channels(testfile_5750_4338)\n",
    "data_5750_4612 = read_hdf5_chunk_channels(testfile_5750_4612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph all channels \n",
    "\n",
    "#graph_all_channels(data_5750_4338)\n",
    "graph_all_channels(data_5750_4612)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LO: 6250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# loading files\n",
    "\n",
    "# time streams\n",
    "testfile_6250_5814 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_6250.0_20240216174729_t_20240216175814.hd5'\n",
    "\n",
    "# tone initializations\n",
    "tone_init_freq_list_6250 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_6250.0_20240216174729/freq_list_lo_sweep_targeted_1_fcenter_6250.0_20240216174925.npy'\n",
    "#tone_init_sweep_targeted = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_targeted_2_fcenter_4250.0_20240216162651.npy'\n",
    "#testfile = \"/Users/leayamashiro/AliCPT/alicpt_data/data_files/ts_toneinit_fcenter_4250.0_20240506174818_t_20240506191017.hd5\"\n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_6250 = np.load(tone_init_freq_list_6250).real # all values still had +0j \n",
    "freq_list_6250_table = pd.DataFrame(freq_list_6250)\n",
    "freq_list_6250_table.to_csv('freq_list_6250.xlsx')\n",
    "\n",
    "# # process data \n",
    "\n",
    "data_6250 = read_hdf5_chunk_channels(testfile_6250_5814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_all_channels(data_6250_5814)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LO: 6750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time streams\n",
    "testfile_6750_0505 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/time_streams/ts_toneinit_fcenter_6750.0_20240216175927_t_20240216180505.hd5'\n",
    "\n",
    "# tone initializations\n",
    "tone_init_freq_list_6750 = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_6750.0_20240216175927/freq_list_lo_sweep_targeted_1_fcenter_6750.0_20240216180053.npy'\n",
    "#tone_init_sweep_targeted = '/Users/leayamashiro/AliCPT/alicpt_data/chopped_data/tone_inits/fcenter_4250.0_20240216162215/lo_sweep_targeted_2_fcenter_4250.0_20240216162651.npy'\n",
    "#testfile = \"/Users/leayamashiro/AliCPT/alicpt_data/data_files/ts_toneinit_fcenter_4250.0_20240506174818_t_20240506191017.hd5\"\n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_6750 = np.load(tone_init_freq_list_6750).real # all values still had +0j \n",
    "\n",
    "# read init files, create csv of values \n",
    "freq_list_6750 = np.load(tone_init_freq_list_6750).real # all values still had +0j \n",
    "freq_list_6750_table = pd.DataFrame(freq_list_6750)\n",
    "freq_list_6750_table.to_csv('freq_list_6750.xlsx')\n",
    "\n",
    "data_6750_0505 = read_hdf5_chunk_channels(testfile_6750_0505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph channels\n",
    "\n",
    "graph_all_channels(data_6750_0505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
