{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.formatter.useoffset'] = False\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from scipy.signal import sawtooth, square, savgol_filter\n",
    "import pandas as pd\n",
    "import glob as gl\n",
    "import os\n",
    "import cmath\n",
    "\n",
    "from scipy.signal import sawtooth, square,find_peaks, savgol_filter\n",
    "from scipy import spatial\n",
    "#import lambdafit as lf\n",
    "from scipy.interpolate import CubicSpline,interp1d\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm as tqdm_terminal\n",
    "from tqdm.notebook import trange, tqdm_notebook\n",
    "from scipy.signal.windows import hann\n",
    "\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from copy import deepcopy\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# for pandas visual number display \n",
    "\n",
    "pd.set_option('display.precision', 6)\n",
    "pd.set_option('display.float_format', '{:.10f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Chunking for Beam-map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Functions for reading, processing, and demodulating real data\n",
    "def read_data(filename, chunk='all', chunk_start=None, chunk_stop=None, single_channel=None):\n",
    "    # read in file\n",
    "    file = h5py.File(filename, 'r') \n",
    "    # pre-setting range for the for-loop iterating to fix the 0-22 rows of resonator buffer \n",
    "    buffer_range_fixed = range(22, (file['time_ordered_data']['adc_i'].shape[0])) \n",
    "    # iterate depending on chunk argument \n",
    "    if chunk == 'all':\n",
    "        ch = np.array([channel - 22 for channel in buffer_range_fixed])\n",
    "        t = np.array(file['time_ordered_data']['timestamp'])\n",
    "        adc_i = np.array([file['time_ordered_data']['adc_i'][channel] for channel in buffer_range_fixed])\n",
    "        adc_q = np.array([file['time_ordered_data']['adc_q'][channel] for channel in buffer_range_fixed])\n",
    "        \n",
    "    elif chunk == 'some': \n",
    "        ch = np.array([channel - 22 for channel in buffer_range_fixed[chunk_start:chunk_stop]])\n",
    "        t = np.array(file['time_ordered_data']['timestamp'])\n",
    "        adc_i = np.array([file['time_ordered_data']['adc_i'][channel] for channel in buffer_range_fixed[chunk_start:chunk_stop]])\n",
    "        adc_q = np.array([file['time_ordered_data']['adc_q'][channel] for channel in buffer_range_fixed[chunk_start:chunk_stop]])\n",
    "        \n",
    "    elif chunk == 'single':\n",
    "        ch = np.array(buffer_range_fixed[single_channel] - 22)\n",
    "        t = np.array(file['time_ordered_data']['timestamp'])\n",
    "        adc_i = np.array(file['time_ordered_data']['adc_i'][buffer_range_fixed[single_channel]])\n",
    "        adc_q = np.array(file['time_ordered_data']['adc_q'][buffer_range_fixed[single_channel]])\n",
    "                              \n",
    "    return t, adc_i, adc_q, ch, file # this function will now have 4 outputs instead of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Correct time segements from .txt (x,y) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1709907709.2978785038</td>\n",
       "      <td>1709907959.6177837849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709907961.6202144623</td>\n",
       "      <td>1709907965.1014409065</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1709907967.1036620140</td>\n",
       "      <td>1709907970.5852940083</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1709907972.5858492851</td>\n",
       "      <td>1709907976.0646548271</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1709907978.0658402443</td>\n",
       "      <td>1709907981.5459232330</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>1709939586.7333009243</td>\n",
       "      <td>1709939590.2120680809</td>\n",
       "      <td>40</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>1709939592.2142755985</td>\n",
       "      <td>1709939595.6955122948</td>\n",
       "      <td>30</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>1709939597.6966049671</td>\n",
       "      <td>1709939601.1780261993</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>1709939603.1804363728</td>\n",
       "      <td>1709939606.6595745087</td>\n",
       "      <td>10</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>1709939608.6617915630</td>\n",
       "      <td>1709939612.1427226067</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5776 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     start                   end   x    y\n",
       "0    1709907709.2978785038 1709907959.6177837849   0    0\n",
       "1    1709907961.6202144623 1709907965.1014409065  10    0\n",
       "2    1709907967.1036620140 1709907970.5852940083  20    0\n",
       "3    1709907972.5858492851 1709907976.0646548271  30    0\n",
       "4    1709907978.0658402443 1709907981.5459232330  40    0\n",
       "...                    ...                   ...  ..  ...\n",
       "5771 1709939586.7333009243 1709939590.2120680809  40  750\n",
       "5772 1709939592.2142755985 1709939595.6955122948  30  750\n",
       "5773 1709939597.6966049671 1709939601.1780261993  20  750\n",
       "5774 1709939603.1804363728 1709939606.6595745087  10  750\n",
       "5775 1709939608.6617915630 1709939612.1427226067   0  750\n",
       "\n",
       "[5776 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_f = '/home/matt/ali_drive_mnt/beam_map_data/toneinit_fcenter_4250.0_20240308061355_t_20240308062133/ts_toneinit_fcenter_4250.0_20240308061355_t_20240308062147.hd5'\n",
    "times_xy = '/home/matt/ali_drive_mnt/beam_map_data/toneinit_fcenter_4250.0_20240308061355_t_20240308062133/beam_map_data_20240308062147.txt'\n",
    "t_xy = pd.read_csv(times_xy, sep=',') # beam map x,y time data raw (starts and ends need correction)\n",
    "t_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_xy = t_xy.rename(columns={' end':'end', ' x': 'x', ' y': 'y'}) # there's a space before \"end\" in the column name, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['start', 'end', 'x', 'y'], dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_xy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.70990771e+09 1.70990796e+09 1.70990797e+09]\n",
      "[1.70990796e+09 1.70990797e+09 1.70990797e+09]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#rearranging\n",
    "\n",
    "# pull out arrays\n",
    "start_1 = np.array(t_xy['start'])\n",
    "stop_1 = np.array(t_xy['end'])\n",
    "# delete first \n",
    "start_1_new = np.delete(start_1, 0)\n",
    "start_1_new = np.pad(start_1_new, (0, 1)) # keep lengths the same, add zero at end (FOR NOW)\n",
    "# confirm\n",
    "print(start_1[0:3])\n",
    "print(start_1_new[0:3])\n",
    "print(start_1[1]==start_1_new[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note here: \n",
    "- the final time (end time of final measurement) is obviously not zero, and needs to be replaced... zero for now?\n",
    "- okay actually no, just going to add average measurement timespan to final \"start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     start                   end   x    y\n",
      "0    1709907709.2978785038 1709907959.6177837849   0    0\n",
      "1    1709907961.6202144623 1709907965.1014409065  10    0\n",
      "2    1709907967.1036620140 1709907970.5852940083  20    0\n",
      "3    1709907972.5858492851 1709907976.0646548271  30    0\n",
      "4    1709907978.0658402443 1709907981.5459232330  40    0\n",
      "...                    ...                   ...  ..  ...\n",
      "5771 1709939586.7333009243 1709939590.2120680809  40  750\n",
      "5772 1709939592.2142755985 1709939595.6955122948  30  750\n",
      "5773 1709939597.6966049671 1709939601.1780261993  20  750\n",
      "5774 1709939603.1804363728 1709939606.6595745087  10  750\n",
      "5775 1709939608.6617915630 1709939612.1427226067   0  750\n",
      "\n",
      "[5776 rows x 4 columns]                      start                   end   x    y\n",
      "0    1709907959.6177837849 1709907961.6202144623   0    0\n",
      "1    1709907965.1014409065 1709907967.1036620140  10    0\n",
      "2    1709907970.5852940083 1709907972.5858492851  20    0\n",
      "3    1709907976.0646548271 1709907978.0658402443  30    0\n",
      "4    1709907981.5459232330 1709907983.5482964516  40    0\n",
      "...                    ...                   ...  ..  ...\n",
      "5771 1709939590.2120680809 1709939592.2142755985  40  750\n",
      "5772 1709939595.6955122948 1709939597.6966049671  30  750\n",
      "5773 1709939601.1780261993 1709939603.1804363728  20  750\n",
      "5774 1709939606.6595745087 1709939608.6617915630  10  750\n",
      "5775 1709939612.1427226067          0.0000000000   0  750\n",
      "\n",
      "[5776 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# set new columns (switch em)\n",
    "\n",
    "start_new = stop_1\n",
    "stop_new = start_1_new \n",
    "\n",
    "t_xy_new = t_xy.copy()\n",
    "t_xy_new['start'] = start_new\n",
    "t_xy_new['end'] = stop_new\n",
    "\n",
    "print(t_xy, t_xy_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(t_xy)):\n",
    "    if t_xy_new['start'][i] != t_xy['end'][i]:\n",
    "        print(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0024306774139404"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_xy_new['end'][0]-t_xy_new['start'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.70990796e+09, 1.70990797e+09, 1.70990797e+09, ...,\n",
       "       1.70993960e+09, 1.70993961e+09, 0.00000000e+00])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = np.hstack([t_xy_new['start'], t_xy_new['end']])\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "\n",
    "for i in range(len(t_xy_new)):\n",
    "    diffs.append(t_xy_new['end'][i] - t_xy_new['start'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average measurement time: 2.0021414247735754\n",
      "stdev of measurement time: 0.00042056351601956295\n",
      "median measurement time: 2.002235174179077\n"
     ]
    }
   ],
   "source": [
    "print('average measurement time: ' + str(np.average(diffs[:-1])))\n",
    "print('stdev of measurement time: ' + str(np.std(diffs[:-1])))\n",
    "print('median measurement time: ' + str(np.median(diffs[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  60.,   86.,   84.,  103.,  101.,  111.,  104.,  214., 3916.,\n",
       "         996.]),\n",
       " array([2.00013256, 2.00038066, 2.00062876, 2.00087686, 2.00112495,\n",
       "        2.00137305, 2.00162115, 2.00186925, 2.00211735, 2.00236545,\n",
       "        2.00261354]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(diffs[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_diffs = []\n",
    "\n",
    "for i in range(len(t_xy)):\n",
    "    orig_diffs.append(t_xy['end'][i] - t_xy['start'][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was trying to verify the measurement times were correct. Going to go with the new dataframe for now but can always go back and change..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5776"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_xy_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read timestream data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, just going to separate them out, later on might be better to have it return a dictionary\n",
    "\n",
    "t, i, q, ch, file = read_data(ts_f,chunk='some', chunk_start=10, chunk_stop=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['attenuator_settings', 'baseband_freqs', 'chan_number', 'chanmask', 'detector_beam_ampl', 'detector_delta_x', 'detector_delta_y', 'detector_dx_dy_elevation_angle', 'detector_pol', 'dfoverf_per_mK', 'ifslice_number', 'lo_freq', 'rfsoc_number', 'sample_rate', 'tile_number', 'tone_powers']>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to find bias line to match up with my channel searching but can't find it... \n",
    "file['global_data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578912 2 2 2\n"
     ]
    }
   ],
   "source": [
    "# look at properties \n",
    "print(len(t), len(i), len(q), len(ch)) \n",
    "\n",
    "# last three will all be 2 because I grabbed two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.70990771e+09, 1.70990771e+09, 1.70990771e+09, ...,\n",
       "       1.70993961e+09, 1.70993961e+09, 1.70993961e+09])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of (t, i, q) for both channels\n",
    "ch_10 = np.asarray((t, (i[0] + 1j*q[0])))\n",
    "ch_11 = np.asarray((t, (i[1] + 1j*q[1]))) \n",
    "\n",
    "# check out time data for channel 10 (taken complex)\n",
    "ch_10[0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.70990771e+09, 1.70990771e+09, 1.70990771e+09, ...,\n",
       "       1.70993961e+09, 1.70993961e+09, 1.70993961e+09])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_10[0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5842092"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3*len(ch_10[0])/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606450/3190745606.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ch10_tchunks = np.asarray(((ch_10[0:int(len(ch_10[0])/4), 0:int(len(ch_10[0])/4)]),\n"
     ]
    }
   ],
   "source": [
    "# breaking into smaller time chunks, just in order to look at smaller bits?\n",
    "ch10_tchunks = np.asarray(((ch_10[0:int(len(ch_10[0])/4), 0:int(len(ch_10[0])/4)]), \n",
    "                          (ch_10[int(len(ch_10[0])/4):int(len(ch_10[0])/2), int(len(ch_10[0])/4):int(len(ch_10[0])/2)]),\n",
    "                          (ch_10[int(len(ch_10[0])/2):int(3*len(ch_10[0])/4), int(len(ch_10[0])/2):int(3*len(ch_10[0])/4)]),\n",
    "                          (ch_10[int(3*(len(ch_10[0])/4)):int(len(ch_10[0])), int(3*(len(ch_10[0])/4)):int(len(ch_10[0]))])\n",
    "                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_10[0]) == len(ch10_tchunks[0][0])*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time start stream: 1709907709.3054738\n",
      "time start mapper: 1709907959.6177838\n",
      "time end stream: 1709939614.9082284\n",
      "time end mapper: 1709939608.6617916\n"
     ]
    }
   ],
   "source": [
    "print('time start stream: ' + str(t[0]))\n",
    "print('time start mapper: ' + str(t_xy_new['start'].iloc[0]))\n",
    "\n",
    "print('time end stream: ' + str(t[-1]))\n",
    "print('time end mapper: ' + str(t_xy_new['end'].iloc[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.local/readout/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1298: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4cee7c60e0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "ch10_chunk1 = ch10_tchunks[0]\n",
    "\n",
    "plt.plot(ch10_chunk1[0], ch10_chunk1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.70990771e+09, 1.70990771e+09, 1.70990771e+09, ...,\n",
       "       1.70991569e+09, 1.70991569e+09, 1.70991569e+09])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working with the first quarter of the time stream \n",
    "\n",
    "t_chunk1 = ch10_chunk1[0].real\n",
    "t_chunk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709915685.7053478"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_chunk1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_idx(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1409"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest_idx(t_xy_new['end'], t_chunk1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606450/211290290.py:12: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.local/readout/lib/python3.10/site-packages/ipykernel/eventloops.py:107: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  app.exec_()\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(t_chunk1, ch10_chunk1[1], lw=0.3, label='timestream signal')\n",
    "for i in range(0,1408):\n",
    "    plt.axvspan(t_xy_new['start'][i], t_xy_new['end'][i], color='red', alpha=0.5)\n",
    "\n",
    "plt.axvspan(t_xy_new['start'][1409], t_xy_new['end'][1409], color='red', alpha=0.5, label='measurement window')\n",
    "plt.ylim(-1000, 5500)\n",
    "plt.xlim(t_chunk1[200000], t_chunk1[220000])\n",
    "plt.xlabel('timestamp (unix)')\n",
    "plt.ylabel('I + jQ signal')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay so now really trying to merge these two sets: \n",
    "\n",
    "def find_nearest_idx(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do I want?\n",
    "1. grab the start and end time stamps from x,y times\n",
    "2. find the index nearest to those in the timestream times\n",
    "3. index the actual signal by those \n",
    "\n",
    "Note: there has to be a < > system so that no signal data is taken from when mapper is moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baby steps: just extract the times first\n",
    "\n",
    "def get_timestream_chunk_idx(t_ts, t_xy_start, t_xy_end):\n",
    "\n",
    "    t_ts = np.asarray(t_ts)\n",
    "\n",
    "    start_range = t_ts[t_ts >= t_xy_start]\n",
    "    end_range = t_ts[t_ts <= t_xy_end]\n",
    "\n",
    "    ts_start_range_idx = (np.abs(start_range - t_xy_start)).argmin()\n",
    "    ts_stop_range_idx = (np.abs(end_range - t_xy_end)).argmin()\n",
    "\n",
    "    ts_start_idx = np.where(t_ts == start_range[ts_start_range_idx])[0][0]\n",
    "    ts_end_idx = np.where(t_ts == end_range[ts_stop_range_idx])[0][0]\n",
    "\n",
    "    return ts_start_idx, ts_end_idx \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t: timestamps from timestream data\n",
    "# t_xy_new: timestamps from mapper position .txt\n",
    "\n",
    "ts_0, ts_1 = get_timestream_chunk_idx(t, t_xy_new['start'][4], t_xy_new['end'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start, end indices result: [132933, 133909]\n",
      "start, end mapper times: [1709907981.5459232, 1709907983.5482965]\n",
      "start, end times indexed from timestream: [1709907981.5476093, 1709907983.5462747]\n"
     ]
    }
   ],
   "source": [
    "print('start, end indices result: ' + str([ts_0, ts_1]))\n",
    "print('start, end mapper times: ' + str([t_xy_new['start'][4], t_xy_new['end'][4]]))\n",
    "print('start, end times indexed from timestream: ' + str([t[ts_0], t[ts_1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_10[0]) == len(ch_10[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay accomplished getting the indices closest between the two time arrays. \n",
    "\n",
    "Now: first rewrite the time chunk index function for retrieving all index points \n",
    "\n",
    "Then: grabbing the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baby steps: just extract the times first\n",
    "\n",
    "# operating on the pandas frame, can change later? \n",
    "# note: trying this out, need to input a much shorter table .... ?\n",
    "\n",
    "def get_timestream_chunk_idx_ALL(t_ts, t_xy_table): # t_xy_starts, t_xy_ends):\n",
    "\n",
    "    t_ts = np.asarray(t_ts)\n",
    "\n",
    "    ts_idxs = []\n",
    "\n",
    "    for i in range(len(t_xy_table)):\n",
    "\n",
    "        t_xy_start = t_xy_table['start'][i]\n",
    "        t_xy_end = t_xy_table['end'][i]\n",
    "\n",
    "        start_range = t_ts[t_ts >= t_xy_start]\n",
    "        end_range = t_ts[t_ts <= t_xy_end]\n",
    "\n",
    "        ts_start_range_idx = (np.abs(start_range - t_xy_start)).argmin()\n",
    "        ts_stop_range_idx = (np.abs(end_range - t_xy_end)).argmin()\n",
    "\n",
    "        ts_start_idx = np.where(t_ts == start_range[ts_start_range_idx])[0][0]\n",
    "        ts_end_idx = np.where(t_ts == end_range[ts_stop_range_idx])[0][0]\n",
    "\n",
    "        ts_idxs.append([ts_start_idx, ts_end_idx])\n",
    "\n",
    "    ts_idxs = np.asarray(ts_idxs)\n",
    "\n",
    "    return ts_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "idxs_test = get_timestream_chunk_idx_ALL(t, t_xy_new.iloc[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122226, 123202],\n",
       "       [124903, 125880],\n",
       "       [127581, 128557],\n",
       "       [130256, 131233],\n",
       "       [132933, 133909],\n",
       "       [135610, 136586],\n",
       "       [138285, 139262],\n",
       "       [140961, 141938],\n",
       "       [143637, 144613],\n",
       "       [146312, 147289],\n",
       "       [148988, 149964]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1709907709.3054738, 1709939614.9082284]\n",
      "[1709907959.61947, 1709907961.6183698]\n"
     ]
    }
   ],
   "source": [
    "print([t[0], t[-1]])\n",
    "print([t[idxs_test][0][0], t[idxs_test][0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15578912"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.local/readout/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1298: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(t[122220:149964], ch_10[1, 122220:149964], lw=0.2, label='timestream signal')\n",
    "\n",
    "for i in range(0,11):\n",
    "    plt.axvspan(t_xy_new['start'][i], t_xy_new['end'][i], color='red', alpha=0.5)\n",
    "    plt.axvline(t[idxs_test[i][0]], color = 'blue')\n",
    "    plt.axvline(t[idxs_test[i][1]], color = 'purple')\n",
    "\n",
    "\n",
    "plt.axvspan(t_xy_new['start'][10], t_xy_new['end'][10], color='red', alpha=0.5, label='measurement window')\n",
    "plt.axvline(t[idxs_test[10][0]], color = 'blue', label = 'nearest timestream start')\n",
    "plt.axvline(t[idxs_test[10][1]], color = 'purple', label = 'nearest timestream end')\n",
    "\n",
    "plt.ylim(-1000, 5500)\n",
    "plt.xlim(t[122200], t[133909])\n",
    "plt.xlabel('timestamp (unix)')\n",
    "plt.ylabel('I + jQ signal')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now actually pulling signal... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['start', 'end', ' x', ' y'], dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_xy_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15578912)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123202"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_test[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([148988, 149964])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ch_10[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1709907959.61947+0j)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[122226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1709908016.4270911+0j)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[149964]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_idx_start = idxs_test[:,0]\n",
    "chunk_idx_end = idxs_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122226, 124903, 127581, 130256, 132933, 135610, 138285, 140961,\n",
       "       143637, 146312, 148988])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ch_ts here is a combined (t, (I + jQ)) array\n",
    "\n",
    "def get_time_chunked_signal(ch_ts, t_xy_table, ts_idxs): \n",
    "\n",
    "    t_ts = ch_ts[0]\n",
    "    iq_ts = ch_ts[1]\n",
    "\n",
    "    chunk_idx_start = ts_idxs[:,0]\n",
    "    chunk_idx_end = ts_idxs[:,1]\n",
    "    \n",
    "    ts_chunks = []\n",
    "\n",
    "    for i in range(len(ts_idxs)):\n",
    "\n",
    "        t_idxed = t_ts[chunk_idx_start[i]:chunk_idx_end[i]]\n",
    "        sig_idxed = iq_ts[chunk_idx_start[i]:chunk_idx_end[i]]\n",
    "\n",
    "        #t_sig_chunked = ch_ts[:, chunk_idx_start[i]:chunk_idx_end[i]]\n",
    "\n",
    "        ts_chunks.append([t_idxed, sig_idxed])\n",
    "        \n",
    "\n",
    "    x_map = np.asarray(t_xy_table['x'])\n",
    "    y_map = np.asarray(t_xy_table['y']) \n",
    "\n",
    "\n",
    "    return x_map, y_map, ts_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, ts_chunked = get_time_chunked_signal(ch_10, t_xy_new.loc[0:11], idxs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_chunked[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_chunked[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2678"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[2][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-plotting to see if I'm getting the right chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(t[122220:149964], ch_10[1, 122220:149964], lw=0.3, label='timestream signal', color='cornflowerblue')\n",
    "\n",
    "for i in range(0,10):\n",
    "    plt.axvspan(t_xy_new['start'][i], t_xy_new['end'][i], color='lightgoldenrodyellow')\n",
    "    plt.axvline(t[idxs_test[i][0]], color = 'blue', lw=3)\n",
    "    plt.axvline(t[idxs_test[i][1]], color = 'maroon', lw=3)\n",
    "\n",
    "    plt.plot(ts_chunked[i][0], ts_chunked[i][1],  color='magenta', lw = 0.5, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.axvspan(t_xy_new['start'][10], t_xy_new['end'][10], color='lightgoldenrodyellow', alpha=0.5, label='measurement window')\n",
    "plt.axvline(t[idxs_test[10][0]], color = 'blue', label = 'nearest timestream start', lw=3)\n",
    "plt.axvline(t[idxs_test[10][1]], color = 'maroon', label = 'nearest timestream end', lw=3)\n",
    "plt.plot(ts_chunked[10][0], ts_chunked[10][1], color = 'magenta', lw = 0.5, alpha=0.5, label = 'signal chunk extracted')\n",
    "\n",
    "plt.ylim(-1000, 5500)\n",
    "#plt.xlim(t[122200], t[133909])\n",
    "plt.xlabel('timestamp (unix)')\n",
    "plt.ylabel('I + jQ signal')\n",
    "plt.legend(loc='upper right', facecolor='white', framealpha=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
